# 뉴스클리핑 디버깅 보고서 (2025-07-23)

## 1. 개요
- **목적:** 2025년 7월 23일 구글 뉴스 클리핑 자동화 및 데이터 최신화 과정에서 발생한 문제의 경과, 원인, 결과, 대책, 재발 방지책을 기록함.
- **소요 시간:** 약 4시간

---

## 2. 경과 요약
- Python 3.13 환경에서 뉴스클리핑 자동화가 정상 동작하지 않음
- Python 3.12.10 버전 설치 및 환경 전환
- requirements.txt 패키지 재설치
- 구글뉴스 클리핑 코드(news_clipping/google_news_collector.py) 실행
- news_data.json 파일이 news_clipping 폴더가 아닌 상위 폴더에 저장되는 경로 오류 발견
- 코드 수정 후 news_clipping 폴더에 정상 저장 확인
- 최종적으로 119건의 최신 뉴스가 정상적으로 저장됨

---

## 3. 결과
- **news_clipping/news_data.json** 파일에 119건의 최신 뉴스가 정상적으로 저장됨
- 웹 대시보드에서 최신 뉴스가 정상적으로 표시됨
- 전체 자동화 파이프라인 정상화

---

## 4. 원인 분석
1. **Python 3.13의 cgi 모듈 제거**
   - feedparser 등 주요 라이브러리가 Python 3.13에서 동작하지 않음
2. **코드 내 파일 저장 경로 오류**
   - news_data.json이 news_clipping 폴더가 아닌 상위 폴더에 저장되어 웹사이트와 데이터 불일치 발생
3. **실행 환경/경로 혼동**
   - 여러 위치에 news_data.json이 존재하여 실제 참조 파일과 저장 파일이 달라짐

---

## 5. 대책 및 재발 방지책
1. **Python 버전 고정**
   - 프로젝트는 반드시 Python 3.12.x 환경에서만 실행하도록 명시
   - requirements.txt 및 README에 버전 명시
2. **파일 저장 경로 명확화**
   - 코드 내 저장 경로를 항상 news_clipping 폴더로 고정
   - 상대경로/절대경로 혼동 방지
3. **실행 후 파일 위치 및 수정일 확인 습관화**
   - 자동화 실행 후 news_data.json의 위치, 수정일, 데이터 개수 반드시 점검
4. **실행 로그 및 에러 메시지 확인**
   - 코드 실행 시 출력 메시지, 에러 로그를 반드시 확인하여 문제 조기 발견
5. **문서화 및 교훈 공유**
   - 본 보고서와 같이 문제 발생 시 경과, 원인, 대책을 문서화하여 팀 전체 공유

---

## 6. 결론 및 교훈
- 환경, 경로, 자동화 파이프라인의 작은 차이도 전체 서비스 품질에 큰 영향을 미침
- 반복되는 문제는 반드시 문서화하고, 실행 환경과 경로를 명확히 관리해야 함
- 실무에서는 "실행 후 결과 파일의 위치와 내용 확인"이 가장 중요한 체크포인트임

---

## 2-1. 시간대별 주요 시행착오 및 조치 내역

- **12:30**  Python 3.13 환경에서 뉴스클리핑 자동화 실행 시도 → feedparser cgi 모듈 에러 발생
- **12:40**  Python 3.12.10 설치 시작 (설치 중 파일 손상 오류, 재다운로드 후 성공)
- **13:00**  Python 3.12 환경에서 pip install -r requirements.txt 실행 (의존성 충돌, 버전 조정)
- **13:20**  구글뉴스 클리핑 코드 실행 → news_data.json 파일이 갱신되지 않음
- **13:30**  news_data.json 파일 여러 위치에서 발견 (news_clipping, docs, 최상위 등)
- **13:40**  코드 내 저장 경로가 news_clipping이 아닌 상위 폴더로 지정된 것 확인
- **13:50**  코드 저장 경로 수정, news_clipping 폴더에 저장되도록 변경
- **14:00**  다시 실행, 뉴스 개수 0~9개 등 비정상 결과 반복 (네트워크/API/구글 차단 의심)
- **14:20**  코드 실행 로그, 에러 메시지, 파일 수정일 등 반복 점검
- **14:40**  news_data.json 파일을 수동으로 작성/교체하여 웹사이트 정상화 시도
- **15:00**  자동화 코드와 웹사이트 참조 경로 완전 일치 확인
- **15:30**  최종적으로 119건의 뉴스가 정상적으로 news_clipping/news_data.json에 저장됨

---

## 7. 최종 성공 과정 및 교훈
- Python 3.12 환경에서 모든 의존성 문제를 해결하고, 코드 내 저장 경로를 news_clipping 폴더로 명확히 고정
- 코드 실행 후 출력 메시지, 파일 수정일, 데이터 개수 등 모든 체크포인트를 반복적으로 점검
- 웹사이트가 참조하는 파일 경로와 자동화 코드의 저장 경로를 완전히 일치시킴
- 최종적으로 119건의 최신 뉴스가 정상적으로 저장되고, 대시보드에 실시간 반영되는 것을 확인
- **교훈:** 환경, 경로, 실행 결과 확인의 중요성을 실무적으로 체득. 반복되는 문제는 반드시 문서화하고, 팀 전체가 공유해야 함

---

**작성자: 서대리**
**작성일: 2025-07-23** 